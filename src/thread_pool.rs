// Copyright (C) 2024  Jimmy Aguilar Mena

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.


#![allow(dead_code)]

use std::sync::{Arc, Mutex, Condvar};
use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};

use std::collections::VecDeque;


/// Represents a task with a unique identifier and a job (a closure) that can be executed.
///
/// The `Task` struct contains an ID and a closure that is executed when the task is run.
/// The ID is assigned atomically to ensure uniqueness, and the job can be executed once.
///
/// The struct uses a static counter to ensure that each `Task` instance has a unique ID.
///
/// # Fields
/// - `id`: A unique identifier for the task, incremented atomically on creation.
/// - `job`: A boxed closure that represents the job to be executed when the task is run.
///
/// # Methods
/// - `counter()`: Returns a reference to a static `AtomicUsize` counter used for generating unique IDs.
/// - `new(job: Box<dyn FnOnce() + Send>) -> Self`: Creates a new task with a unique ID and the provided closure.
/// - `execute(self)`: Executes the job (closure) stored in the task. Once executed, the task is consumed.
struct Task {
    id: usize,
    job: Box<dyn FnOnce() + Send>,
}

impl Task {
    /// Returns a reference to a static `AtomicUsize` counter for generating unique IDs for tasks.
    ///
    /// The counter is used to ensure each `Task` instance has a unique ID, incrementing atomically.
    fn counter() -> &'static AtomicUsize {
        static COUNTER: AtomicUsize = AtomicUsize::new(0);
        &COUNTER
    }

    /// Creates a new `Task` with a unique ID and the provided job (closure).
    ///
    /// The `id` is generated by atomically incrementing a static counter.
    /// The provided job is stored as a `Box<dyn FnOnce() + Send>` to be executed later.
    ///
    /// # Parameters
    /// - `job`: A boxed closure that represents the job to be executed by the task.
    ///
    /// # Returns
    /// A new instance of `Task` with a unique ID and the provided job.
    fn new(job: Box<dyn FnOnce() + Send>) -> Self {
        let id = Self::counter().fetch_add(1, Ordering::Relaxed);
        Self { id, job }
    }

    /// Executes the task's job (closure).
    ///
    /// The task is consumed when this method is called, and the job (closure) is executed.
    fn execute(self) {
        (self.job)();
    }
}


/// Represents a worker thread in a thread pool, responsible for executing tasks.
///
/// The `Worker` struct encapsulates a worker thread that runs tasks from a shared task queue.
/// Each worker operates within a thread pool and communicates with a controller to handle task execution and synchronization.
///
/// # Fields
/// - `id`: A unique identifier for the worker.
/// - `thread`: An `Option` holding the `JoinHandle` for the worker's thread, allowing it to be joined later when the thread completes.
///
/// # Methods
/// - `new(id: usize, controler: Arc<ThreadPoolControlers>) -> Self`: Creates a new `Worker` with the given ID and control structure, starting a new thread that will process tasks.
struct Worker {
    id: usize,
    thread: Option<std::thread::JoinHandle<()>>,
}

impl Worker {
    /// Creates a new worker thread that continuously processes tasks from a shared queue.
    ///
    /// This method spawns a new thread, which runs in an infinite loop, processing tasks as they arrive in the queue.
    /// The worker thread waits for tasks to be available and processes them as long as the thread pool is active. 
    /// When there are no tasks or when the thread pool is deactivated, the worker will exit.
    ///
    /// The worker interacts with the `ThreadPoolControlers` to manage task synchronization and coordination.
    /// Tasks are taken from the `queue` under a lock, and the worker waits on a condition variable when the queue is empty.
    /// The worker will continue to process tasks as long as the pool is active and the queue has tasks to process.
    ///
    /// The worker's thread will notify the controler when all tasks have been executed.
    ///
    /// # Parameters
    /// - `id`: A unique identifier for the worker.
    /// - `controler`: An `Arc` containing the control structure for the thread pool, which handles synchronization and task management.
    ///
    /// # Returns
    /// A new `Worker` instance with a spawned thread responsible for executing tasks.
    fn new(id: usize, controler: Arc<ThreadPoolControlers>) -> Self {
        println!("Creating Worker: {}", id);

        let thread = std::thread::spawn(move || {

            println!("Worker {} Running", id);
            'outter: loop {

                loop {
                    // The task needs to be taken independently of the
                    // match, because when inlined in the match it
                    // looks like the match holds the lock.
                    let task = {
                        let mut lock = controler.queue.lock().unwrap();

                        // The thread will be here in the condition
                        // variable until someone notifies that there
                        // is some work to do or sets active to false.
                        while lock.is_empty() && controler.active.load(Ordering::Relaxed) {
                            lock = controler.cv.wait(lock).unwrap();
                        };

                        if lock.is_empty() {
                            break 'outter
                        }

                        // Update the atomic, this trick is to avoid
                        // taking the lock on every task finalization
                        // to notify taskwait.
                        controler.running.fetch_add(1, Ordering::Relaxed);

                        // We can pop_front even in empty queues.
                        // When the queue is empty we are here because
                        // active was set to false and we want to
                        // exit. However, we don't do that check here
                        // to avoid holding the lock for longer.
                        lock.pop_front()
                    };

                    match task {
                        Some(task) => {
                            println!(" -> Worker {} got task {}", id, task.id);
                            task.execute();

                            // When all the tasks are executed in the
                            // thread pool, we notify in case there is a
                            // taskwait blocking anything.
                            if controler.running.fetch_sub(1, Ordering::Relaxed) == 1 {
                                let _lock = controler.queue.lock().unwrap();
                                controler.cv.notify_all();
                            }
                        },
                        None => { break 'outter } // Exiting worker when no tasks are left
                    }
                }
            }
            println!("Worker {} Done", id);
        });

        Self { id, thread: Some(thread) }
    }
}

struct ThreadPoolControlers {
    queue: Mutex<VecDeque<Task>>,
    running: AtomicUsize,
    active: AtomicBool,
    cv: Condvar,
}

/// A ThreadPool that manages a collection of worker threads.
///
/// This struct is used to execute tasks concurrently using a fixed number of threads.
/// The pool is capable of submitting tasks, executing them asynchronously, and 
/// synchronizing task execution using a scope. It also provides functionality to 
/// wait for tasks to finish.
///
/// # Methods
///
/// - `new(size: usize)`: Creates a new `ThreadPool` with a specified number of worker threads.
/// - `new_default()`: Creates a new `ThreadPool` with a number of threads based on the available parallelism.
/// - `submit(job: Box<dyn FnOnce() + Send>)`: Submits a task to the pool.
/// - `execute<F>(f: F)`: Executes a closure by submitting it to the pool.
/// - `scope<'scope, F>(fout: F)`: Executes a scope, ensuring tasks in the scope are completed before exiting.
/// - `taskwait()`: Waits for all tasks in the queue to finish execution.
pub struct ThreadPool {
    workers: Vec<Worker>,
    controler: Arc<ThreadPoolControlers>,
}

impl ThreadPool {
    /// Creates a new `ThreadPool` with a fixed number of threads.
    ///
    /// # Arguments
    /// - `size`: The number of worker threads to create.
    ///
    /// # Panics
    /// Panics if the `size` is zero.
    pub fn new(size: usize) -> Self {
        assert!(size > 0);

        let controler = Arc::new(
            ThreadPoolControlers {
                queue: Mutex::new(VecDeque::<Task>::new()),
                running: AtomicUsize::new(0),
                active: AtomicBool::new(true),
                cv: Condvar::new(),
            }
        );

        let workers = (0..size)
            .map(|i| Worker::new(i, Arc::clone(&controler)))
            .collect();

        Self { workers, controler }
    }

    /// Creates a new `ThreadPool` with the default number of threads based on system parallelism.
    pub fn new_default() -> Self {
        let n_threads = std::thread::available_parallelism().unwrap().get();
        Self::new(n_threads)
    }

    /// Submits a task to the pool to be executed by a worker thread.
    ///
    /// # Arguments
    /// - `job`: A boxed closure that implements `FnOnce() + Send` to be executed.
    fn submit(&self, job: Box<dyn FnOnce() + Send>) {
        let mut guard = self.controler.queue.lock().unwrap();
        guard.push_back(Task::new(job));

        if guard.len() == 1 {
            // Wake up threads that may be sleeping
            self.controler.cv.notify_all();
        }
    }

    /// Executes a task by submitting it to the pool.
    ///
    /// # Arguments
    /// - `f`: A closure implementing `FnOnce() + Send` to be executed by the pool.
    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        self.submit(Box::new(f));
    }

    /// Executes a closure within a scope, ensuring all tasks in the scope are completed.
    ///
    /// # Arguments
    /// - `f`: A closure that accepts a `PoolScopeData` reference and performs work within the scope.
    pub fn scope<'scope, F>(&'scope self, f: F)
    where
      F: FnOnce(&PoolScopeData<'scope>),
    {
        let scope = PoolScopeData::new(&self);
        f(&scope);
        scope.taskwait();
    }

    /// Waits for all tasks in the queue to finish execution.
    pub fn taskwait(&self) {
        let mut guard = self.controler.queue.lock().unwrap();
        while guard.len() > 0 {
            guard = self.controler.cv.wait(guard).unwrap();
        }
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        self.controler.active.store(false, Ordering::Relaxed);

        // Notify inactive threads to exit
        self.controler.cv.notify_all();

        // Wait for all tasks to finish
        self.taskwait();

        // Join all worker threads
        self.workers
            .iter_mut()
            .for_each(|worker| worker.thread.take().unwrap().join().unwrap());
    }
}

struct PoolScopeControls {
    num_pending_tasks: AtomicUsize,
    scope_mutex: Mutex<()>,
    cv: Condvar,
}

pub(crate) struct PoolScopeData<'scope> {
    thread_pool: &'scope ThreadPool,
    controls: Arc<PoolScopeControls>
}

impl<'scope> PoolScopeData<'scope> {

    pub(crate) fn new(pool: &'scope ThreadPool) -> Self
    {
        Self {
            thread_pool: &pool,
            controls: Arc::new(
                PoolScopeControls {
                    num_pending_tasks: AtomicUsize::new(0),
                    scope_mutex: Mutex::new(()),
                    cv: Condvar::new()
                }
            ),
        }
    }

    pub fn spawn<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'scope + 'static,
    {
        self.controls.num_pending_tasks.fetch_add(1, Ordering::SeqCst);
        let controls = Arc::clone(&self.controls);

        let job = Box::new(move || {

            f();

            // Notify for counter in scope finalization.  The last
            // task in the scope will notify in case there is a
            // taskwait blocking the scope code.
            if controls.num_pending_tasks.fetch_sub(1, Ordering::SeqCst) == 1 {
                let _guard = controls.scope_mutex.lock().unwrap();
                controls.cv.notify_one();
            }

        });

        self.thread_pool.submit(job);
    }

    pub fn taskwait(&self)
    {
        let mut guard = self.controls.scope_mutex.lock().unwrap();

        while self.controls.num_pending_tasks.load(Ordering::SeqCst) > 0 {
            guard = self.controls.cv.wait(guard).unwrap();
        }
    }
}

impl<'a> Drop for PoolScopeData<'a>
{
    fn drop(&mut self) {
        assert_eq!(self.controls.num_pending_tasks.load(Ordering::SeqCst), 0);
    }
}


#[cfg(test)]
mod matrix_borrow {

    use super::*;
    use std::time::Duration;

    #[test]
    fn pool_test()
    {
        let pool = ThreadPool::new(4);

        for i in 0..8 {
            pool.execute(move || {
                println!("\tTask {} is running.", i);
            });
        }
    }

    #[test]
    fn pool_taskwait_fast()
    {
        let pool = ThreadPool::new(4);

        for i in 0..8 {
            pool.execute(move || {
                println!("\tBefore {} is running.", i);
            });
        }

        pool.taskwait();
        println!("=== Taskwait!!!===");

        for i in 9..18 {
            println!("Submitting {}!", i);
            pool.execute(move || {
                println!("\tAfter {} is running.", i);
            });
        }
    }

    #[test]
    fn pool_taskwait_timer()
    {
        let pool = ThreadPool::new(4);

        for i in 0..8 {
            pool.execute(move || {
                println!("\tBefore {} is running.", i);
                std::thread::sleep(Duration::from_millis(500));
            });
        }

        pool.taskwait();
        println!("=== Taskwait!!!===");

        for i in 9..18 {
            println!("Submitting {}!", i);
            pool.execute(move || {
                println!("\tAfter {} is running.", i);
                std::thread::sleep(Duration::from_millis(500));
            });
        }

    }

    #[test]
    fn pool_scope_fast()
    {
        let pool = ThreadPool::new(4);

        pool.scope(move |s| {
            for i in 0..8 {
                s.spawn(move || {
                    println!("\tTask {} is running.", i);
                });
            }
        }
        );

    }

    #[test]
    fn pool_scope_timer()
    {
        let pool = ThreadPool::new(4);

        pool.scope(move |s| {
            for i in 0..16 {
                s.spawn(move || {
                    println!("\tTask {} is running.", i);
                    std::thread::sleep(Duration::from_millis(500));
                });
            }
        });
    }

    #[test]
    fn pool_scope_taskwait()
    {
        let pool = ThreadPool::new(4);

        pool.scope(move |s| {
            for i in 0..8 {
                s.spawn(move || {
                    println!("\tBefore {} is running.", i);
                    std::thread::sleep(Duration::from_millis(500));
                });
            }

            s.taskwait();
            println!("=== Taskwait!!!===");

            for i in 9..16 {
                println!("Submitting {}!", i);
                s.spawn(move || {
                    println!("\tAfter {} is running.", i);
                    std::thread::sleep(Duration::from_millis(500));
                });
            }
        });
    }
}

